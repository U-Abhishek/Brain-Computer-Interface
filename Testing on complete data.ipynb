{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ls1_QPAmusUZ"
   },
   "outputs": [],
   "source": [
    "## analyse the data\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the paper**  \n",
    "'1023': 1 (Rejected trial),   \n",
    " '1072': 2 (Eye movements),  \n",
    " '276':  3 (eyes open)),  \n",
    " '277':  4 (eyes closed),   \n",
    " '32766':5 (Start of a new run),  \n",
    " '768':  6 (Start of a trial),  \n",
    " '769': 7 LEFT (class 1),  \n",
    " '770': 8 RIGHT (class 2),  \n",
    " '771': 9 FOOT (class 3),  \n",
    " '772': 10 TONGUE (class 4)\n",
    "#### event ids are not same for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TitH-M4tCYx9"
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    raw=mne.io.read_raw_gdf(path,preload=True,\n",
    "                          eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    raw.set_eeg_reference()\n",
    "    events, event_id =mne.events_from_annotations(raw)\n",
    "    #events[1]['769'],events[1]['770'],events[1]['771'],events[1]['772']\n",
    "    ann = event_id.keys()\n",
    "    ann = list(map(int,ann))\n",
    "    ids = event_id.values()\n",
    "    ids = list(ids)\n",
    "    unq = np.unique(events[:,-1])\n",
    "    for u in unq:\n",
    "        events[:,-1] = np.where(events[:,-1]== u , ann[u-1],events[:,-1])\n",
    "    epochs = mne.Epochs(raw, events, event_id=[769,772],\n",
    "                        tmin= 0, tmax=4,baseline=(None,4), on_missing ='warn')\n",
    "    labels=epochs.events[:,-1]\n",
    "    features=epochs.get_data()\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BCICIV_2a_gdf\\\\A01T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A02T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A03T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A04T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A05T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A06T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A07T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A08T.gdf',\n",
       " 'BCICIV_2a_gdf\\\\A09T.gdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = glob.glob('BCICIV_2a_gdf/*T.gdf')\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xW0kIs4CEqlx"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "features,labels,groups=[],[],[]\n",
    "for i in paths:\n",
    "    feature,label=read_data(i)\n",
    "    features.append(feature)\n",
    "    labels.append(label)\n",
    "    groups.append([i]*len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 22, 1001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CXhty7XLz3P",
    "outputId": "89d63f5d-50ad-4c51-a592-e7c006f0c898",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['BCICIV_2a_gdf\\\\A01T.gdf', 'BCICIV_2a_gdf\\\\A02T.gdf',\n",
       "        'BCICIV_2a_gdf\\\\A03T.gdf', 'BCICIV_2a_gdf\\\\A04T.gdf',\n",
       "        'BCICIV_2a_gdf\\\\A05T.gdf', 'BCICIV_2a_gdf\\\\A06T.gdf',\n",
       "        'BCICIV_2a_gdf\\\\A07T.gdf', 'BCICIV_2a_gdf\\\\A08T.gdf',\n",
       "        'BCICIV_2a_gdf\\\\A09T.gdf'], dtype='<U22'),\n",
       " array([144, 144, 144, 144, 144, 144, 144, 144, 144], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(groups, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([769, 772]), array([648, 648], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "unique, counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "gkf=GroupKFold()\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#https://stackoverflow.com/questions/50125844/how-to-standard-scale-a-3d-matrix\n",
    "class StandardScaler3D(BaseEstimator,TransformerMixin):\n",
    "    #batch, sequence, channels\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.scaler.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.scaler.transform(X.reshape( -1,X.shape[2])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([769, 772])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(features, labels):\n",
    "    # \n",
    "    scaler=StandardScaler3D()\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    label_array = []\n",
    "    for f in range(len(features)):\n",
    "        features[f] =np.moveaxis(features[f],1,2)\n",
    "        print(features[f].shape)\n",
    "        features[f] = scaler.fit_transform(features[f])\n",
    "        features[f] =np.moveaxis(features[f],1,2)\n",
    "        # lable binarizer\n",
    "        label_array.append(lb.fit_transform(labels[f]))\n",
    "    return features , label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n",
      "(144, 1001, 22)\n"
     ]
    }
   ],
   "source": [
    "data_array, label_array = data_processing(data_array, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 22, 1001, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 1001, 8)       512       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 22, 1001, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_1 (Depthwi  (None, 1, 1001, 16)      352       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1, 1001, 16)      64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1, 1001, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 1, 250, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 250, 16)        0         \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 1, 250, 16)       512       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1, 250, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1, 250, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 1, 31, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 31, 16)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 496)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 497       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,033\n",
      "Trainable params: 1,953\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eegnet = tf.keras.models.load_model('Models/eegnet_LT_0.8885.h5')\n",
    "eegnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90        72\n",
      "           1       0.86      0.99      0.92        72\n",
      "\n",
      "    accuracy                           0.91       144\n",
      "   macro avg       0.92      0.91      0.91       144\n",
      "weighted avg       0.92      0.91      0.91       144\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "y_p = []\n",
    "pred = eegnet.predict_on_batch(data_array[i])\n",
    "pred = pred.reshape(pred.shape[0])\n",
    "for l in pred:\n",
    "    if l>0.5:\n",
    "        y_p.append(1)\n",
    "    else:\n",
    "        y_p.append(0)\n",
    "y_t = label_array[i].reshape(label_array[i].shape)\n",
    "print(classification_report(y_t, y_p))\n",
    "cf_matrix = confusion_matrix(y_t, y_p)\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(model,x,y):\n",
    "    accuracy = []\n",
    "    for i in range(len(x)):\n",
    "        y_p = []\n",
    "        pred = model.predict_on_batch(x[i])\n",
    "        pred = pred.reshape(pred.shape[0])\n",
    "        for l in pred:\n",
    "            if l>0.5:\n",
    "                y_p.append(1)\n",
    "            else:\n",
    "                y_p.append(0)\n",
    "        y_t = y[i].reshape(y[i].shape)\n",
    "        acc = accuracy_score(y_t, y_p)\n",
    "        accuracy.append(acc)\n",
    "    accuracy = np.array(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = find_accuracy(eegnet,data_array,label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88888889, 0.79861111, 0.97222222, 0.90972222, 0.90277778,\n",
       "       0.88888889, 0.91666667, 0.95138889, 0.97222222])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9112654320987653"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BCI Competition 2008 â€“ Graz data set A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
